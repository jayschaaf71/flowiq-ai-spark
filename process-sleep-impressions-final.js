import Papa from 'papaparse';
import { createClient } from '@supabase/supabase-js';
import fs from 'fs';
import path from 'path';

async function processSleepImpressions() {
  console.log('ğŸš€ Processing Sleep Impressions Data (Final Version)...');

  try {
    // Initialize Supabase client
    const supabase = createClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL,
      process.env.SUPABASE_SERVICE_ROLE_KEY
    );

    // Define the files to process (from today's upload)
    const files = [
      'billing_log_2025-08-11_10-23-50.csv',
      'claims_for_collections_rpt\'_2025-08-11_10-26-42.csv',
      'insurance_pat_ref_report_2025-08-11_10-25-52.csv',
      'patient_visit_log_2025-08-11_10-24-49.csv'
    ];

    const downloadsPath = path.join(process.env.HOME, 'Downloads');
    
    console.log('ğŸ“ Processing files from:', downloadsPath);

    // Create a summary object
    const summary = {
      totalFiles: files.length,
      processedFiles: 0,
      totalRecords: 0,
      errors: [],
      dataSamples: {}
    };

    // Process each file
    for (const fileName of files) {
      const filePath = path.join(downloadsPath, fileName);
      
      if (!fs.existsSync(filePath)) {
        console.log(`âŒ File not found: ${fileName}`);
        summary.errors.push(`File not found: ${fileName}`);
        continue;
      }

      try {
        console.log(`\nğŸ”„ Processing: ${fileName}`);

        // Read and parse CSV
        const csvContent = fs.readFileSync(filePath, 'utf-8');
        const parseResult = Papa.parse(csvContent, { 
          header: true, 
          skipEmptyLines: true,
          transform: (value) => value.trim() // Clean whitespace
        });

        const data = parseResult.data;
        console.log(`âœ… Parsed ${data.length} rows`);

        // Store data sample
        if (data.length > 0) {
          summary.dataSamples[fileName] = {
            columns: Object.keys(data[0]),
            sampleRow: data[0],
            recordCount: data.length
          };
        }

        summary.totalRecords += data.length;
        summary.processedFiles++;

        console.log(`âœ… Successfully processed ${fileName}`);

      } catch (fileError) {
        console.error(`âŒ Error processing ${fileName}:`, fileError.message);
        summary.errors.push(`${fileName}: ${fileError.message}`);
      }
    }

    // Print summary
    console.log('\nï¿½ï¿½ ETL PROCESS SUMMARY:');
    console.log('========================');
    console.log(`ğŸ“Š Total files: ${summary.totalFiles}`);
    console.log(`âœ… Processed files: ${summary.processedFiles}`);
    console.log(`ğŸ“ˆ Total records: ${summary.totalRecords}`);
    console.log(`âŒ Errors: ${summary.errors.length}`);

    if (summary.errors.length > 0) {
      console.log('\nâŒ Errors encountered:');
      summary.errors.forEach(error => console.log(`  - ${error}`));
    }

    console.log('\nğŸ“‹ Data Structure Summary:');
    console.log('==========================');
    Object.entries(summary.dataSamples).forEach(([fileName, data]) => {
      console.log(`\nğŸ“ ${fileName}:`);
      console.log(`   Records: ${data.recordCount}`);
      console.log(`   Columns: ${data.columns.join(', ')}`);
      console.log(`   Sample: ${JSON.stringify(data.sampleRow, null, 2)}`);
    });

    // Save summary to file
    const summaryFile = 'etl-summary.json';
    fs.writeFileSync(summaryFile, JSON.stringify(summary, null, 2));
    console.log(`\nğŸ’¾ Summary saved to: ${summaryFile}`);

    console.log('\nğŸ‰ Sleep Impressions ETL Complete!');
    console.log('\nğŸ“‹ NEXT STEPS:');
    console.log('1. Review the data structure above');
    console.log('2. Create database tables based on the column structure');
    console.log('3. Implement data insertion logic');
    console.log('4. Set up automated processing');

  } catch (error) {
    console.error('âŒ ETL process failed:', error.message);
  }
}

// Run the process
processSleepImpressions().catch(console.error);
